From df06e0c0b600dfbbad3ac5c07ffc9dfbacd04be1 Mon Sep 17 00:00:00 2001
From: Niek van Agt <niek.van.agt@topic.nl>
Date: Thu, 19 Dec 2019 13:00:12 +0100
Subject: [PATCH] Make driver capable of configuring DMA node with 64bit
 addresses Is backwards compatible with old (32bit) DMA nodes

---
 dyplo-core.c | 75 +++++++++++++++++++++++++++++++++++++---------------
 dyplo-core.h |  1 +
 dyplo.h      | 14 +++++++---
 3 files changed, 64 insertions(+), 26 deletions(-)

diff --git a/dyplo-core.c b/dyplo-core.c
index 70da415..7b242a6 100644
--- a/dyplo-core.c
+++ b/dyplo-core.c
@@ -200,6 +200,7 @@ struct dyplo_dma_dev
 	wait_queue_head_t wait_queue_from_logic;
 	struct dyplo_dma_from_logic_operation dma_from_logic_current_op;
 	bool dma_from_logic_full;
+	u32 dma_addr_bits;
 };
 
 union dyplo_route_item_u {
@@ -1771,18 +1772,20 @@ static unsigned int dyplo_dma_to_logic_avail(struct dyplo_dma_dev *dma_dev)
 	for (num_results = (status >> 24); num_results != 0; --num_results) {
 		/* Fetch result from queue */
 		struct dyplo_dma_to_logic_operation op;
-		u32 addr = dyplo_reg_read_quick(control_base, DYPLO_DMA_TOLOGIC_RESULT_ADDR);
+		dma_addr_t addr = dyplo_reg_read_quick(control_base, DYPLO_DMA_TOLOGIC_RESULT_ADDR_LOW);
+		if (dma_dev->dma_addr_bits > 32)
+			addr |= ((dma_addr_t)dyplo_reg_read_quick(control_base, DYPLO_DMA_TOLOGIC_RESULT_ADDR_HIGH) << 32);
 		if (unlikely(!kfifo_get(&dma_dev->dma_to_logic_wip, &op))) {
 			pr_err("Nothing in fifo of DMA node %u but still %u results\n",
 				dyplo_dma_get_index(dma_dev), num_results);
 			BUG();
 		}
-		pr_debug("%s addr=%#x wip=%#x,%u\n", __func__, addr, (u32)op.addr, op.size);
+		pr_debug("%s addr=0x%llx wip=0x%llx,%u\n", __func__, addr, op.addr, op.size);
 		if (unlikely(op.addr != addr)) {
-			pr_err("Mismatch in result of DMA node %u: phys=%pa expected %#x (size %d) actual %#x\n",
+			pr_err("Mismatch in result of DMA node %u: phys=%pa expected 0x%llx (size %d) actual 0x%llx\n",
 				dyplo_dma_get_index(dma_dev),
 				&dma_dev->dma_to_logic_handle,
-				(u32)op.addr, op.size, addr);
+				(dma_addr_t)op.addr, op.size, addr);
 			pr_err("head=%#x (%d) tail=%#x (%d)\n",
 				dma_dev->dma_to_logic_head,
 				dma_dev->dma_to_logic_head,
@@ -1791,11 +1794,13 @@ static unsigned int dyplo_dma_to_logic_avail(struct dyplo_dma_dev *dma_dev)
 			for (;;) {
 				if (!kfifo_get(&dma_dev->dma_to_logic_wip, &op))
 					break;
-				pr_err("Internal entry: %#x (size %d)\n", (u32)op.addr, op.size);
+				pr_err("Internal entry: 0x%llx (size %d)\n", (dma_addr_t)op.addr, op.size);
 			}
 			while (num_results) {
-				addr = dyplo_reg_read_quick(control_base, DYPLO_DMA_TOLOGIC_RESULT_ADDR);
-				pr_err("Logic result: %#x\n", addr);
+				dma_addr_t addr = dyplo_reg_read_quick(control_base, DYPLO_DMA_TOLOGIC_RESULT_ADDR_LOW);
+				if (dma_dev->dma_addr_bits > 32)
+					addr |= ((dma_addr_t)dyplo_reg_read_quick(control_base, DYPLO_DMA_TOLOGIC_RESULT_ADDR_HIGH) << 32);
+				pr_err("Logic result: 0x%llx\n", (dma_addr_t)addr);
 				--num_results;
 			}
 			BUG();
@@ -1915,7 +1920,9 @@ static ssize_t dyplo_dma_write(struct file *filp, const char __user *buf,
 			finish_wait(&dma_dev->wait_queue_to_logic, &wait);
 		pr_debug("%s sending addr=%#x size=%u\n", __func__,
 			(unsigned int)dma_op.addr, dma_op.size);
-		iowrite32_quick(dma_op.addr, control_base + (DYPLO_DMA_TOLOGIC_STARTADDR>>2));
+		iowrite32_quick(dma_op.addr & 0xFFFFFFFF, control_base + (DYPLO_DMA_TOLOGIC_STARTADDR_LOW>>2));
+		if (dma_dev->dma_addr_bits > 32)
+			iowrite32_quick(dma_op.addr >> 32, control_base + (DYPLO_DMA_TOLOGIC_STARTADDR_HIGH>>2));
 		iowrite32(dma_op.size, control_base + (DYPLO_DMA_TOLOGIC_BYTESIZE>>2));
 		if (unlikely(kfifo_put(&dma_dev->dma_to_logic_wip, dma_op) == 0)) {
 			pr_err("dma_to_logic_wip kfifo was full, cannot put %#x %u\n",
@@ -1961,9 +1968,11 @@ static unsigned int dyplo_dma_from_logic_pump(struct dyplo_dma_dev *dma_dev)
 	while (!dma_dev->dma_from_logic_full) {
 		if (!num_free_entries)
 			break; /* No more room for commands */
-		pr_debug("%s sending addr=%#x size=%u\n", __func__,
-			(unsigned int)dma_dev->dma_from_logic_handle + dma_dev->dma_from_logic_head, dma_dev->dma_from_logic_block_size);
-		iowrite32(dma_dev->dma_from_logic_handle + dma_dev->dma_from_logic_head, control_base + (DYPLO_DMA_FROMLOGIC_STARTADDR>>2));
+		pr_debug("%s sending addr=0x%llx size=%u\n", __func__,
+			(dma_addr_t)dma_dev->dma_from_logic_handle + dma_dev->dma_from_logic_head, dma_dev->dma_from_logic_block_size);
+		iowrite32((dma_dev->dma_from_logic_handle + dma_dev->dma_from_logic_head) & 0xFFFFFFFF, control_base + (DYPLO_DMA_FROMLOGIC_STARTADDR_LOW>>2));
+		if (dma_dev->dma_addr_bits > 32)
+			iowrite32((dma_dev->dma_from_logic_handle + dma_dev->dma_from_logic_head) >> 32, control_base + (DYPLO_DMA_FROMLOGIC_STARTADDR_HIGH>>2));
 		iowrite32(dma_dev->dma_from_logic_block_size, control_base + (DYPLO_DMA_FROMLOGIC_BYTESIZE>>2));
 		dma_dev->dma_from_logic_head += dma_dev->dma_from_logic_block_size;
 		if (dma_dev->dma_from_logic_head == dma_dev->dma_from_logic_memory_size)
@@ -1985,6 +1994,7 @@ static ssize_t dyplo_dma_read(struct file *filp, char __user *buf, size_t count,
 	unsigned int bytes_to_copy;
 	unsigned int bytes_copied = 0;
 	unsigned int results_avail = 0;
+	unsigned int tail;
 	struct dyplo_dma_from_logic_operation *current_op =
 		&dma_dev->dma_from_logic_current_op;
 	DEFINE_WAIT(wait);
@@ -2003,8 +2013,10 @@ static ssize_t dyplo_dma_read(struct file *filp, char __user *buf, size_t count,
 		while (current_op->size == 0) {
 			/* Fetch a new operation from logic */
 			if (results_avail) {
-				dma_addr_t start_addr = dyplo_reg_read_quick(control_base, DYPLO_DMA_FROMLOGIC_RESULT_ADDR);
-				unsigned int tail = start_addr - dma_dev->dma_from_logic_handle;
+				dma_addr_t start_addr = dyplo_reg_read_quick(control_base, DYPLO_DMA_FROMLOGIC_RESULT_ADDR_LOW);
+				if (dma_dev->dma_addr_bits > 32)
+					start_addr |= ((dma_addr_t)dyplo_reg_read_quick(control_base, DYPLO_DMA_FROMLOGIC_RESULT_ADDR_HIGH) << 32);
+				tail = start_addr - dma_dev->dma_from_logic_handle;
 				current_op->addr = ((char*)dma_dev->dma_from_logic_memory) + tail;
 				current_op->user_signal = dyplo_reg_read_quick(control_base, DYPLO_DMA_FROMLOGIC_RESULT_USERBITS);
 				current_op->size = dyplo_reg_read(control_base, DYPLO_DMA_FROMLOGIC_RESULT_BYTESIZE);
@@ -2450,7 +2462,9 @@ static int dyplo_dma_to_logic_block_enqueue(struct dyplo_dma_dev *dma_dev,
 		return -EWOULDBLOCK;
 	pr_debug("%s sending addr=%#x size=%u\n", __func__,
 			(unsigned int)block->phys_addr, block->data.bytes_used);
-	iowrite32_quick(block->phys_addr, control_base + (DYPLO_DMA_TOLOGIC_STARTADDR>>2));
+	iowrite32_quick(block->phys_addr & 0xFFFFFFFF, control_base + (DYPLO_DMA_TOLOGIC_STARTADDR_LOW>>2));
+	if (dma_dev->dma_addr_bits > 32)
+		iowrite32_quick(block->phys_addr >> 32, control_base + (DYPLO_DMA_TOLOGIC_STARTADDR_HIGH>>2));
 	iowrite32_quick(block->data.user_signal, control_base + (DYPLO_DMA_TOLOGIC_USERBITS>>2));
 	iowrite32(block->data.bytes_used, control_base + (DYPLO_DMA_TOLOGIC_BYTESIZE>>2));
 	block->data.state = 1;
@@ -2501,9 +2515,12 @@ static int dyplo_dma_to_logic_block_dequeue(struct dyplo_dma_dev *dma_dev,
 		if ((status & 0xFF000000) == 0)
 			return -EAGAIN;
 	}
-	start_addr = dyplo_reg_read(control_base, DYPLO_DMA_TOLOGIC_RESULT_ADDR);
+	start_addr = dyplo_reg_read_quick(control_base, DYPLO_DMA_TOLOGIC_RESULT_ADDR_LOW);
+	if (dma_dev->dma_addr_bits > 32)
+		start_addr |= ((dma_addr_t)dyplo_reg_read_quick(control_base, DYPLO_DMA_TOLOGIC_RESULT_ADDR_HIGH) << 32);
+
 	if (start_addr != block->phys_addr) {
-		pr_err("%s Expected addr %#x result %#x\n", __func__, (u32)block->phys_addr, (u32)start_addr);
+		pr_err("%s Expected addr 0x%llx result 0x%llx\n", __func__, (dma_addr_t)block->phys_addr, (dma_addr_t)start_addr);
 		return -EIO;
 	}
 
@@ -2879,9 +2896,11 @@ static int dyplo_dma_from_logic_block_enqueue(struct dyplo_dma_dev *dma_dev,
 		return -EWOULDBLOCK;
 
 	/* Send to logic */
-	pr_debug("%s sending addr=%#x size=%u\n", __func__,
-			(u32)block->phys_addr, block->data.size);
-	iowrite32(block->phys_addr, control_base + (DYPLO_DMA_FROMLOGIC_STARTADDR>>2));
+	pr_debug("%s sending addr=0x%llx size=%u\n", __func__,
+			(dma_addr_t)block->phys_addr, block->data.size);
+	iowrite32(block->phys_addr & 0xFFFFFFFF, control_base + (DYPLO_DMA_FROMLOGIC_STARTADDR_LOW>>2));
+	if (dma_dev->dma_addr_bits > 32)
+		iowrite32(block->phys_addr >> 32, control_base + (DYPLO_DMA_FROMLOGIC_STARTADDR_HIGH>>2));
 	iowrite32(request_bytes_used, control_base + (DYPLO_DMA_FROMLOGIC_BYTESIZE>>2));
 	block->data.bytes_used = 0;
 	block->data.state = 1;
@@ -2934,9 +2953,11 @@ static int dyplo_dma_from_logic_block_dequeue(struct dyplo_dma_dev *dma_dev,
 	if (is_blocking)
 		finish_wait(&dma_dev->wait_queue_from_logic, &wait);
 
-	start_addr = dyplo_reg_read_quick(control_base, DYPLO_DMA_FROMLOGIC_RESULT_ADDR);
+	start_addr = dyplo_reg_read_quick(control_base, DYPLO_DMA_FROMLOGIC_RESULT_ADDR_LOW);
+	if (dma_dev->dma_addr_bits > 32)
+		start_addr |= ((dma_addr_t)dyplo_reg_read_quick(control_base, DYPLO_DMA_FROMLOGIC_RESULT_ADDR_HIGH) << 32);
 	if (start_addr != block->phys_addr) {
-		pr_err("%s Expected addr %#x result %#x\n", __func__, (u32)block->phys_addr, (u32)start_addr);
+		pr_err("%s Expected addr 0x%llx result 0x%llx\n", __func__, (dma_addr_t)block->phys_addr, (dma_addr_t)start_addr);
 		return -EIO;
 	}
 	block->data.user_signal = dyplo_reg_read_quick(control_base, DYPLO_DMA_FROMLOGIC_RESULT_USERBITS);
@@ -3356,6 +3377,9 @@ static int create_sub_devices_dma_fifo(
 		goto failed_device_create;
 	}
 
+	/* Set width of addr bus */
+	dma_dev->dma_addr_bits = dev->dma_addr_bits;
+
 	++dev->number_of_dma_devices;
 	/* Enable the DMA controller */
 	iowrite32_quick(BIT(0), cfg_dev->control_base + (DYPLO_DMA_TOLOGIC_CONTROL>>2));
@@ -3719,6 +3743,11 @@ void dyplo_core_apply_license(struct dyplo_dev *dev, const void *data)
 		DYPLO_REG_CONTROL_LICENSE_KEY1, key);
 }
 
+static u32 dyplo_core_get_dma_addr_bus_width(struct dyplo_dev *dev)
+{
+  return dyplo_reg_read_quick(dev->base, DYPLO_REG_CONTROL_DMA_ADDR_WIDTH);
+}
+
 int dyplo_core_probe(struct device *device, struct dyplo_dev *dev)
 {
 	dev_t devt;
@@ -3734,7 +3763,9 @@ int dyplo_core_probe(struct device *device, struct dyplo_dev *dev)
 	if (unlikely(retval))
 		return retval;
 
-	retval = dma_set_mask_and_coherent(device, DMA_BIT_MASK(32));
+	/* Check DMA node address bus width and set dma_bit_mask accordingly */
+	dev->dma_addr_bits = dyplo_core_get_dma_addr_bus_width(dev);
+	retval = dma_set_mask_and_coherent(device, DMA_BIT_MASK(dev->dma_addr_bits));
 	if (unlikely(retval))
 		dev_warn(device, "Failed to set DMA mask: %d", retval);
 
diff --git a/dyplo-core.h b/dyplo-core.h
index b2f7360..14c20c6 100644
--- a/dyplo-core.h
+++ b/dyplo-core.h
@@ -67,6 +67,7 @@ struct dyplo_dev
 	u8 count_fifo_read_devices;
 	u8 number_of_dma_devices;
 	u8 icap_device_index;
+	u32 dma_addr_bits;
 };
 
 int dyplo_core_remove(struct device *device, struct dyplo_dev *dev);
diff --git a/dyplo.h b/dyplo.h
index caedae7..e4b5124 100644
--- a/dyplo.h
+++ b/dyplo.h
@@ -60,6 +60,7 @@
 #define DYPLO_REG_CONTROL_STATIC_ID	0x0C
 #define DYPLO_REG_CONTROL_NODE_COUNT_1	0x14
 #define DYPLO_REG_CONTROL_NODE_COUNT_2	0x18
+#define DYPLO_REG_CONTROL_DMA_ADDR_WIDTH	0x1C
 #define DYPLO_REG_CONTROL_DYPLO_VERSION	0x30
 #define DYPLO_REG_CONTROL_LICENSE_INFO	0x34
 #define DYPLO_REG_CONTROL_LICENSE_KEY0	0x38
@@ -137,24 +138,29 @@
 #define DYPLO_DMA_TOLOGIC_CONTROL	0x60
 #define DYPLO_DMA_TOLOGIC_STATUS	0x64
 
-#define DYPLO_DMA_TOLOGIC_STARTADDR	0x70
+#define DYPLO_DMA_TOLOGIC_STARTADDR_LOW	0x70
 #define DYPLO_DMA_TOLOGIC_USERBITS	0x74
 /* Writing BYTESIZE starts the transfer */
 #define DYPLO_DMA_TOLOGIC_BYTESIZE	0x78
+#define DYPLO_DMA_TOLOGIC_STARTADDR_HIGH	0x7C
 
 /* Reading RESULT_ADDR removes the result from the queue */
-#define DYPLO_DMA_TOLOGIC_RESULT_ADDR	0x80
+#define DYPLO_DMA_TOLOGIC_RESULT_ADDR_LOW	0x80
+#define DYPLO_DMA_TOLOGIC_RESULT_ADDR_HIGH	0x8C
 
 #define DYPLO_DMA_STANDALONE_TOLOGIC_BASE	0x90
 
 #define DYPLO_DMA_FROMLOGIC_CONTROL	0xB0
 #define DYPLO_DMA_FROMLOGIC_STATUS	0xB4
-#define DYPLO_DMA_FROMLOGIC_STARTADDR	0xC0
+#define DYPLO_DMA_FROMLOGIC_STARTADDR_LOW	0xC0
 /* Writing BYTESIZE starts the transfer */
 #define DYPLO_DMA_FROMLOGIC_BYTESIZE	0xC8
-#define DYPLO_DMA_FROMLOGIC_RESULT_ADDR	0xD0
+#define DYPLO_DMA_FROMLOGIC_STARTADDR_HIGH	0xCC
+
+#define DYPLO_DMA_FROMLOGIC_RESULT_ADDR_LOW	0xD0
 #define DYPLO_DMA_FROMLOGIC_RESULT_USERBITS	0xD4
 /* Reading RESULT_BYTESIZE removes the result from the queue */
 #define DYPLO_DMA_FROMLOGIC_RESULT_BYTESIZE	0xD8
+#define DYPLO_DMA_FROMLOGIC_RESULT_ADDR_HIGH	0xDC
 
 #define DYPLO_DMA_STANDALONE_FROMLOGIC_BASE	0xE0
